name: Saturday Drive Backup (folders + spreadsheets)

on:
  workflow_dispatch:
  schedule:
    - cron: "0 18 * * 6"          # Saturdays 18 UTC ≈ 19 CET

jobs:
  backup:
    runs-on: ubuntu-latest

    env:
      WEEKLY_DEST_FOLDER: "1aoSe5seTsCGSn_2gDjU3SiFxlTwAFMmw"
      TRANSFERS: "10"      # drop if you hit rate limits
      CHECKERS:  "20"
      CLEAN_DEST: "0"      # ← set to 1 if you want a full wipe *before* copying

    steps:
    # ───── prepare credentials ─────
    - uses: actions/checkout@v3
    - name: Stage service‑account creds
      run: cp web-portal-automator-src/credentials.json ./creds.json
    # ───── rclone configuration ─────
    - name: Install rclone
      run: curl https://rclone.org/install.sh | sudo bash
    - name: Write rclone config
      run: |
        mkdir -p ~/.config/rclone
        cat > ~/.config/rclone/rclone.conf <<EOF
        [src]
        type = drive
        scope = drive
        service_account_file = ./creds.json
        [dst]
        type = drive
        scope = drive
        service_account_file = ./creds.json
        root_folder_id = ${WEEKLY_DEST_FOLDER}
        EOF
    # ───── copy folder trees ─────
    - name: Copy 6 folder trees
      id: folders
      run: |
        set -e
        TODAY=$(date -u +%d.%m.%Y)
        DEST="dst:${TODAY}"

        # optional: wipe existing dated folder for a clean snapshot
        if [ "$CLEAN_DEST" = "1" ]; then
          echo "Purging existing $DEST …"
          rclone purge "$DEST" || true
        fi

        # ensure dated folder exists (idempotent if already there)
        rclone mkdir "$DEST"

        FOLDERS=(
          16VQxSSw_Zybv7GtFMhQgzyzyE5EEX9gb     # Leads
          10lXwcwYGsbdIYLhkL9862RP4Xi1L-p9v     # Daily_Backup
          17O23nAlgh2fnlBcIBmk2K7JBeUAAQZfB     # Resume
          1-sVtj8AdMB7pQAadjB9_CUmQ67gOXswi     # Job KPIs
          1g6FARH-wKNk9o0s74X60cifwcc6YDqoP
          1GSWRpzm9OMNQF7Wbcgr7cLE5zX8gPEbO
        )

        for ID in "${FOLDERS[@]}"; do
          # wrap raw ID in { } so rclone treats it as Drive‑ID
          rclone copy \
            --drive-chunk-size 64M \
            --transfers ${TRANSFERS} \
            --checkers  ${CHECKERS} \
            --drive-use-trash=false \
            --create-empty-src-dirs \
            "src:{${ID}}" \
            "$DEST/$ID" &
        done
        wait
        echo "folders_done=1" >> $GITHUB_OUTPUT
    # ───── copy seven spreadsheets ─────
    - uses: actions/setup-python@v4
      if: steps.folders.outputs.folders_done == '1'
      with:
        python-version: "3.10"

    - name: Install Google client
      if: steps.folders.outputs.folders_done == '1'
      run: |
        python -m pip install --upgrade pip
        python -m pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib

    - name: Copy 7 standalone spreadsheets
      if: steps.folders.outputs.folders_done == '1'
      working-directory: web-portal-automator-src
      run: python weekly_backup_files.py
    # ───── done ─────
    - name: Finished
      run: echo "✅ Weekly Drive backup finished (folders merged${{ env.CLEAN_DEST == '1' && ' after purge' || '' }} + spreadsheets)."
